# ActionGuardians

&#x20;&#x20;

> **End-to-End Human Activity Recognition** using smartphone accelerometer & gyroscope data

---

## ğŸ“Œ Table of Contents

1. [Project Overview](#project-overview)
2. [Pipeline Architecture](#pipeline-architecture)
3. [Results](#results)
4. [Demo](#demo)
5. [Installation & Usage](#installation--usage)
6. [Project Structure](#project-structure)
7. [Future Work](#future-work)
8. [Contributing](#contributing)
9. [License](#license)

---

## ğŸš€ Project Overview

**Objective**: Real-time recognition of six human activitiesâ€”walking, running, sitting, standing, upstairs, downstairsâ€”from smartphone sensor data.

* **Dataset**

  * **Source**: Self-collected (50Â Hz sampling rate)
  * **Features**: `acc_x`, `acc_y`, `acc_z`, `gyro_x`, `gyro_y`, `gyro_z`
  * **Samples**: \~2,500 sliding-window instances (Test set: 115 windows)
  * **Labels**: 6 balanced classes

---

## ğŸ›  Pipeline Architecture

### 1. Data Collection

* Raw CSV with columns: `id`, `timestamp`, `seconds_elapsed`, sensor axes, `label`.

### 2. Preprocessing

* **DataPreprocessor** class:

  * Cleans unwanted columns
  * Generates sliding windows (`window_size`, `step_size`)
  * Assigns dominant label per window

### 3. Feature Extraction

* **Time-domain**: mean, std, min, max, median, energy
* **Jerk**: Î”signal Ã— sampling\_rate (mean, std, energy)
* **Zero crossings** count
* **Frequency-domain**: FFT (mean, max, std)

### 4. Model Training

* **Algorithm**: `RandomForestClassifier`
* **Hyperparameters**: `n_estimators=100`, `max_depth=None`, `random_state=42`
* **Tracking**: MLflow for experiment logging & artifact storage

### 5. Deployment

* **FastAPI** server:

  * Endpoint: `/predict` (accepts two CSVs, returns JSON summary)
* **Flask** UI:

  * User authentication & session management
  * CSV upload interface
  * Interactive summary charts & tables

---

## ğŸ“ˆ Results

| Metric    | Value |
| --------- | ----- |
| Accuracy  | 1.00  |
| Precision | 1.00  |
| Recall    | 1.00  |
| F1-Score  | 1.00  |

**Confusion Matrix (Test Set)**&#x20;

---

<!-- ## ğŸ¬ Demo

[![Watch the Demo](https://img.youtube.com/vi/<VIDEO_ID>/0.jpg)](https://youtu.be/<VIDEO_ID>) -->

## ğŸ–¥ï¸ UI Screenshots

#### Login Page

![Login Page](images/1.png)

#### Registration Page

![Registration Page](images/2.png)

#### Dashboard Home

![Dashboard Home](images/3.png)

#### Activity Prediction Form

![Prediction Form](images/4.png)

#### Prediction Summary

![Prediction Summary](images/5.png)

## ğŸ’» Installation & Usage

1. **Clone the repo**

   ```bash
   git clone https://github.com/<username>/ActionGuardians.git
   cd ActionGuardians
   ```

2. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

3. **Preprocess & Train**

   ```bash
   python scripts/preprocess.py    # Generates X_windows.npy & y_labels.npy
   python scripts/train.py         # Trains model and logs to MLflow
   ```

4. **Start FastAPI**

   ```bash
   uvicorn api.main:app --reload
   ```

5. **Launch Flask UI**

   ```bash
   cd ui
   flask run
   ```

6. **Access Dashboard**

   * Visit `http://localhost:5000`
   * Login default: `admin` / `password123` (change in `.env`)

---

## ğŸ“‚ Project Structure

```
ActionGuardians/
â”œâ”€â”€ __pycache__/            # Python bytecode cache
â”œâ”€â”€ config/                # Global configuration files
â”œâ”€â”€ images/                # Visual assets (plots, diagrams, screenshots)
â”œâ”€â”€ logs/                  # Log files
â”œâ”€â”€ notebooks/             # Jupyter notebooks
â”œâ”€â”€ services/              # Background services or utility scripts
â”œâ”€â”€ src_actionguardian/    # Core application source code
â”‚   â”œâ”€â”€ __pycache__/       # Cached Python files
â”‚   â”œâ”€â”€ components/        # UI components (Flask templates logic)
â”‚   â”œâ”€â”€ config/            # Application-specific configs
â”‚   â”œâ”€â”€ constants/         # Constant definitions
â”‚   â”œâ”€â”€ entity/            # Data models and schemas
â”‚   â”œâ”€â”€ pipeline/          # Preprocessing & training pipeline code
â”‚   â””â”€â”€ utils/             # Utility functions
â”œâ”€â”€ static/                # Static assets (CSS, JS)
â”œâ”€â”€ templates/             # HTML templates
â”‚   â”œâ”€â”€ dashboard.html
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ login.html
â”‚   â”œâ”€â”€ predict.html
â”‚   â””â”€â”€ register.html
â”œâ”€â”€ venv/                  # Virtual environment
â”œâ”€â”€ .env                   # Environment variables
â”œâ”€â”€ .gitignore             # Git ignore rules
â”œâ”€â”€ app.py                 # Flask UI entrypoint
â”œâ”€â”€ fast_api_server.py     # FastAPI server entrypoint
â”œâ”€â”€ main.py                # Orchestrator script (if used)
â”œâ”€â”€ params.yaml            # Parameter definitions for pipelines
â”œâ”€â”€ schema.yaml            # Data schema definitions
â”œâ”€â”€ schemas.py             # Pydantic schemas
â”œâ”€â”€ template.py            # Template utilities
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # Project documentation
```

<!-- ---

## ğŸ”® Future Work

* Data augmentation: noise injection, rotation, scaling
* Deep learning: CNN/LSTM experiments
* Mobile-app integration: real-time inference
* CI/CD pipeline: GitHub Actions â†’ Docker â†’ AWS/GCP

--- -->

## ğŸ¤ Contributing

Contributions welcome! Please open issues and PRs for improvements, features, or bug fixes.

---

## ğŸ“œ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.
